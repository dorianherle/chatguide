================================================================================
CONSOLIDATED CHATBOT CODE
All Python files needed to run the chatbot system
================================================================================

FILES INCLUDED:
1. main.py
2. yaml_reader.py
3. prompt.py
4. llm.py
5. schema.py
6. chatbot_config.yaml
7. data_schema.yaml
8. requirements.txt

================================================================================

==================== MAIN.PY ====================
-----------------------------------------------

from yaml_reader import read_yaml_to_dict
import json
from prompt import get_prompt_conversation_llm, get_prompt_sidecar_director
from llm import talk_to_gemini, talk_to_gemini_structured
import os
from dotenv import load_dotenv

class Chatbot:
    def __init__(self, config_path='chatbot_config.yaml', persona="You are a friendly and engaging chatbot. Keep sentences very short and concise.", debug=False, sidecar_update_interval=3):
        load_dotenv()
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.config = read_yaml_to_dict(config_path)
        self.persona = persona
        self.conversation = ""
        self.to_extract = self.config['blocks'][0]['fields']
        self.next_extraction_block = self.config['blocks'][1]['fields']
        self.turn_count = 0
        self.sidecar_response = None
        self.debug = debug
        self.sidecar_update_interval = sidecar_update_interval

    def log(self, message):
        if self.debug:
            with open("chatbot_log.txt", "a", encoding="utf-8") as f:
                f.write(message + "\n")

    def start(self):
        # Initial setup
        initial_sidecar_prompt = get_prompt_sidecar_director(self.conversation, self.to_extract, self.next_extraction_block)
        self.log("=== INITIAL SIDECAR PROMPT ===")
        self.log(initial_sidecar_prompt)

        self.sidecar_response = talk_to_gemini_structured(initial_sidecar_prompt, api_key=self.api_key)
        self.log("=== INITIAL SIDECAR RESPONSE ===")
        self.log(json.dumps(self.sidecar_response.model_dump(), indent=2))

        conversation_prompt = get_prompt_conversation_llm(self.persona, self.conversation, self.sidecar_response.stage_direction)
        self.log("=== CONVERSATION PROMPT ===")
        self.log(conversation_prompt)

        response = talk_to_gemini(conversation_prompt, api_key=self.api_key)
        self.log("=== CONVERSATION RESPONSE ===")
        self.log(response)

        self.conversation += "You: " + response + "\n"
        return response

    def chat(self, user_input):
        self.conversation += "User: " + user_input + "\n"
        self.turn_count += 1

        # Update sidecar every N turns
        if self.turn_count % self.sidecar_update_interval == 0:
            self.log("=== UPDATING SIDECAR PROMPT ===")
            sidecar_prompt = get_prompt_sidecar_director(self.conversation, self.to_extract, self.next_extraction_block)
            self.log(sidecar_prompt)

            self.sidecar_response = talk_to_gemini_structured(sidecar_prompt, api_key=self.api_key)
            self.log("=== SIDECAR RESPONSE ===")
            self.log(json.dumps(self.sidecar_response.model_dump(), indent=2))

            print("=== SIDECAR RESPONSE ===")
            print(json.dumps(self.sidecar_response.model_dump(), indent=4))

        conversation_prompt = get_prompt_conversation_llm(self.persona, self.conversation, self.sidecar_response.stage_direction)
        self.log("=== CONVERSATION PROMPT ===")
        self.log(conversation_prompt)

        response = talk_to_gemini(conversation_prompt, api_key=self.api_key)
        self.log("=== CONVERSATION RESPONSE ===")
        self.log(response)

        self.conversation += "You: " + response + "\n"

        return response

# Usage example
if __name__ == "__main__":
    bot = Chatbot(debug=True)
    response = bot.start()

    while True:
        print("Bot: " + response)
        user_input = input("You: ")
        response = bot.chat(user_input)


================================================================================

==================== YAML_READER.PY ====================
------------------------------------------------------

import yaml
import json

def read_yaml_to_dict(file_path):
    with open(file_path, 'r') as file:
        data = yaml.safe_load(file)
    return data

# Example usage
if __name__ == "__main__":
    config_dict = read_yaml_to_dict('chatbot_config.yaml')
    # pretty print the config_dict
    print(json.dumps(config_dict, indent=4))


================================================================================

==================== PROMPT.PY ====================
-------------------------------------------------

### Prompt Conversation LLM ###


def get_prompt_conversation_llm(persona: str, conversation:str, mandate: str) -> str:
    return f"""
Persona
{persona}
Conversation so far:
{conversation}
Mandate
{mandate}

Be clever. Don't directly ask the user all questions in the mandate. You can take multiple turns to ask the questions in the mandate.
I mean be socially smart, look at the conversation so far and the mandate and come up with a natural conversation flow.
"""

### Prompt Sidecar Director ###
def get_prompt_sidecar_director(conversation: str, current_extraction_block, next_extraction_block) -> str:
    # Format the current fields
    def format_current_fields(fields):
        if isinstance(fields, list):
            formatted_lines = []
            for field in fields:
                if isinstance(field, dict):
                    name = field.get('name', 'Unknown')
                    question = field.get('question', 'No question')
                    validation = field.get('validation', '')
                    if validation and validation != 'No validation':
                        formatted_lines.append(f"- {name}: {question} (must be {validation})")
                    else:
                        formatted_lines.append(f"- {name}: {question}")
                else:
                    formatted_lines.append(f"- {field}")
            return '\n'.join(formatted_lines)
        return fields

    # Format the next fields
    def format_next_fields(fields):
        if isinstance(fields, list):
            formatted_lines = []
            for field in fields:
                if isinstance(field, dict):
                    name = field.get('name', 'Unknown')
                    question = field.get('question', 'No question')
                    formatted_lines.append(f"- {name}: {question}")
                else:
                    formatted_lines.append(f"- {field}")
            return '\n'.join(formatted_lines)
        return fields

    formatted_current_fields = format_current_fields(current_extraction_block)
    formatted_next_fields = format_next_fields(next_extraction_block)

    return f"""You are the Director of a roleplay.

Your job has TWO STRICTLY SEPARATED responsibilities.

----------------------------------------
1) EXTRACTION (CURRENT BLOCK ONLY)
----------------------------------------

Below is the CURRENT EXTRACTION BLOCK.
You may extract values ONLY for the fields listed here.

CURRENT EXTRACTION BLOCK FIELDS:
{formatted_current_fields}

Rules:
- Extract ONLY values explicitly stated in the conversation.
- Do NOT infer, assume, normalize, or guess.
- If a field is not explicitly mentioned, DO NOT include it.
- If none of the fields are mentioned, return an empty object {{}}.
- NEVER extract fields that are not listed in the CURRENT EXTRACTION BLOCK.

Return extracted values under the key "extracted".

----------------------------------------
2) STAGE DIRECTION (CONDITIONAL)
----------------------------------------

You must generate ONE stage direction for the conversation LLM.

Step 1 — Check CURRENT BLOCK completeness:
- If one or more fields from the CURRENT EXTRACTION BLOCK are missing or unclear:
  -> The stage direction MUST guide the bot to naturally elicit ONLY those missing fields.

Step 2 — If and ONLY IF the CURRENT BLOCK is fully complete:
- Shift the stage direction toward the NEXT EXTRACTION BLOCK below.
- Do NOT extract these fields yet.
- The goal is to naturally encourage the user to mention them next.

NEXT EXTRACTION BLOCK FIELDS:
{formatted_next_fields}

Rules for stage direction:
- Do NOT use a checklist or interrogation style.
- Be conversational and natural.
- Instructions must be directed at the Bot.
- Instructions MUST start with: "You need to..."

Return the instruction under the key "stage_direction".

----------------------------------------
CONVERSATION:
{conversation}

----------------------------------------
OUTPUT FORMAT (JSON ONLY):
{{
  "extracted": {{}},
  "stage_direction": "..."
}}"""

================================================================================

==================== LLM.PY ====================
----------------------------------------------

from google import genai
from schema import ExtractionResponse

def talk_to_gemini(prompt: str, api_key: str = None) -> str:
    """Send a prompt to Gemini and get a response"""

    # Create Gemini client
    client = genai.Client(api_key=api_key)


    # Send prompt and get response
    response = client.models.generate_content(
        model="gemini-2.5-flash-lite",
        contents=prompt,
    )

    # Return the text response
    return response.text

def talk_to_gemini_structured(prompt: str, api_key: str = None) -> ExtractionResponse:
    """Send a prompt to Gemini and get a structured response"""
    import json
  

    # Create Gemini client
    client = genai.Client(api_key=api_key)

    # Configure the model
    config = {
        "response_mime_type": "application/json",
        "response_json_schema": ExtractionResponse.model_json_schema(),
    }

    # Send prompt and get response
    response = client.models.generate_content(
        model="gemini-2.5-flash-lite",
        contents=prompt,
        config=config,
    )

    # Parse and validate the JSON response
    response_data = json.loads(response.text)
    return ExtractionResponse(**response_data)

================================================================================

==================== SCHEMA.PY ====================
-------------------------------------------------

from pydantic import BaseModel, Field
from typing import Dict, Any

class ExtractionResponse(BaseModel):
    """
    Schema for the sidecar director's response containing extracted values and stage direction.
    """
    extracted: Dict[str, Any] = Field(description="Dictionary mapping field names to their extracted values")
    stage_direction: str = Field(description="Instructions for the conversation LLM to steer the conversation forward")


================================================================================

==================== CHATBOT_CONFIG.YAML ====================
-----------------------------------------------------------

blocks:
  - name: "personal_info"
    description: "Extract basic personal information"
    turns_threshold: 3
    fields:
      - name: "name"
        question: "What is your name?"

      - name: "age"
        question: "How old are you?"

        validation: "is_integer and 0 < value < 90"

      - name: "origin"
        question: "Where are you from?"


  - name: "preferences"
    description: "Extract user preferences and interests"
    turns_threshold: 4
    fields:
      - name: "favorite_color"
        question: "What is your favorite color?"

      - name: "hobby"
        question: "What is your favorite hobby?"

      - name: "music_genre"
        question: "What music genre do you prefer?"


  - name: "goals"
    description: "Extract user goals and aspirations"
    turns_threshold: 3
    fields:
      - name: "short_term_goal"
        question: "What is a short-term goal you have?"
  
      - name: "long_term_goal"
        question: "What is a long-term goal you have?"



================================================================================

==================== DATA_SCHEMA.YAML ====================
--------------------------------------------------------

ystem_persona: "You are a friendly and engaging conversational chatbot named Gearbox. Your goal is to have natural, entertaining conversations while gently extracting information from the user. Be conversational and fun, not interrogative."

blocks:
  - description: "Extract basic personal information"
    fields:
      - key: "name"
      - key: "age"
      - key: "origin"

  - description: "Extract user preferences and interests"
    fields:
      - key: "favorite_color"
      - key: "hobby"
      - key: "music_genre"

  - description: "Extract user goals and aspirations"
    fields:
      - key: "short_term_goal"
      - key: "long_term_goal"



================================================================================

==================== REQUIREMENTS.TXT ====================
--------------------------------------------------------

google-genai
python-dotenv
pyyaml
streamlit
colorama
pydantic


================================================================================

